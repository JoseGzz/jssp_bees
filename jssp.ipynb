{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic = {'PUN':[], 'REST':[], 'ApVt':[], 'HyR': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CPM(nx.DiGraph):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._dirty = True\n",
    "        self._makespan = -1\n",
    "        self._criticalPath = None\n",
    "\n",
    "    def add_node(self, *args, **kwargs):\n",
    "        self._dirty = True\n",
    "        super().add_node(*args, **kwargs)\n",
    "\n",
    "    def add_nodes_from(self, *args, **kwargs):\n",
    "        self._dirty = True\n",
    "        super().add_nodes_from(*args, **kwargs)\n",
    "\n",
    "    def add_edge(self, *args):  # , **kwargs):\n",
    "        self._dirty = True\n",
    "        super().add_edge(*args)  # , **kwargs)\n",
    "\n",
    "    def add_edges_from(self, *args, **kwargs):\n",
    "        self._dirty = True\n",
    "        super().add_edges_from(*args, **kwargs)\n",
    "\n",
    "    def remove_node(self, *args, **kwargs):\n",
    "        self._dirty = True\n",
    "        super().remove_node(*args, **kwargs)\n",
    "\n",
    "    def remove_nodes_from(self, *args, **kwargs):\n",
    "        self._dirty = True\n",
    "        super().remove_nodes_from(*args, **kwargs)\n",
    "\n",
    "    def remove_edge(self, *args):  # , **kwargs):\n",
    "        self._dirty = True\n",
    "        super().remove_edge(*args)  # , **kwargs)\n",
    "\n",
    "    def remove_edges_from(self, *args, **kwargs):\n",
    "        self._dirty = True\n",
    "        super().remove_edges_from(*args, **kwargs)\n",
    "\n",
    "    def _forward(self):\n",
    "        for n in nx.topological_sort(self):\n",
    "            S = max([self.node[j]['C']\n",
    "                     for j in self.predecessors(n)], default=0)\n",
    "            self.add_node(n, S=S, C=S + self.node[n]['p'])\n",
    "\n",
    "    def _backward(self):\n",
    "        for n in nx.topological_sort(self, reverse=True):\n",
    "            Cp = min([self.node[j]['Sp']\n",
    "                      for j in self.successors(n)], default=self._makespan)\n",
    "            self.add_node(n, Sp=Cp - self.node[n]['p'], Cp=Cp)\n",
    "\n",
    "    def _computeCriticalPath(self):\n",
    "        G = set()\n",
    "        for n in self:\n",
    "            if self.node[n]['C'] == self.node[n]['Cp']:\n",
    "                G.add(n)\n",
    "        self._criticalPath = self.subgraph(G)\n",
    "\n",
    "    @property\n",
    "    def makespan(self):\n",
    "        if self._dirty:\n",
    "            self._update()\n",
    "        return self._makespan\n",
    "\n",
    "    @property\n",
    "    def criticalPath(self):\n",
    "        if self._dirty:\n",
    "            self._update()\n",
    "        return self._criticalPath\n",
    "\n",
    "    def _update(self):\n",
    "        self._forward()\n",
    "        self._makespan = max(nx.get_node_attributes(self, 'C').values())\n",
    "        self._backward()\n",
    "        self._computeCriticalPath()\n",
    "        self._dirty = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_nodes(processes):\n",
    "    \"\"\"genera un conjunto de nodos sin conexiones\n",
    "    processes: lista de tuplas de la forma (id proceso, tiempo)\"\"\"\n",
    "    graph_nodes = CPM() # creamos un nuevo objeto grafo\n",
    "    for process in processes: # creamos los nodos con su id y tiempo\n",
    "        graph_nodes.add_node(process[0], p=process[1])\n",
    "    return graph_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_random_solution(graph_nodes, no_processes, no_requests):\n",
    "    \"\"\"generamos una solucion aleatoria agregando arcos a los nodos creados\n",
    "    graph_nodes: grafo que contiene los nodos sin conexion\n",
    "    no_processes: cantidad de procesos\n",
    "    no_requests: cantidad de pedidos\"\"\"\n",
    "    # obtenemos lista en orden de los nodos\n",
    "    nodes = graph_nodes.nodes()\n",
    "    # creamos lista de listas vacias para organizar el orden de los procesos en comun\n",
    "    node_list = [[] for _ in range(no_processes)]\n",
    "    # separamos los nodos de procesos que pertenecen a cada pedido \n",
    "    adjacency_list = [nodes[i:i + no_processes] for i in range(0, len(nodes), no_processes)]\n",
    "    # creamos los arcos para unir los nodos en el orden establecido por el proceso\n",
    "    for lst in adjacency_list:\n",
    "        for i in range(len(lst)-1):\n",
    "            graph_nodes.add_edges_from([(lst[i], lst[i+1])])\n",
    "    # agrupamos los nodos que pertenecen a la misma operacion para asignarlas al azar\n",
    "    nodes = graph_nodes.nodes()\n",
    "    for i in range(len(node_list)):\n",
    "        for j in range(i, len(nodes), no_processes):\n",
    "            node_list[i].append(nodes[j])\n",
    "    # asignar el orden de uso de cada estacion aleatoriamente\n",
    "    for common_processes in node_list:\n",
    "        random.shuffle(common_processes)\n",
    "        for i in range(len(common_processes)-1):\n",
    "            graph_nodes.add_edges_from([(common_processes[i], common_processes[i+1])])\n",
    "    # regresamos el grafo con precedencias\n",
    "    return graph_nodes, node_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perturbate_solution(graph, node_list, patch_size):\n",
    "    \"\"\"creamos una configuracion similar a la actual\n",
    "    graph: el bjeto que representa al grafo\n",
    "    node_list: configuracion de la solucion; lista con el orden de los procesos\n",
    "    path_size: 'cantidad' de variabilidad\"\"\"\n",
    "    # aplicambios patch_size cantidad de cambios\n",
    "    while patch_size > 0:\n",
    "        # seleccionamos un proceso aleatorio para modificar su orden\n",
    "        selected_process = random.randint(0, len(node_list)-1)\n",
    "        # obtenemos los nodos involucrados en el proceso seleccionado\n",
    "        nodes = node_list[selected_process]\n",
    "        #print(node_list)\n",
    "        # creamos una lista de tuplas con esos nodos para eliminar sus conexiones\n",
    "        tup_list = []\n",
    "        for i in range(len(nodes)-1):\n",
    "            tup_list.append((nodes[i], nodes[i+1]))\n",
    "        # eliminamos las conexiones entre esos nodos\n",
    "        graph.remove_edges_from(tup_list)\n",
    "        # generamos un nuevo orden aleatorio\n",
    "        random.shuffle(nodes)\n",
    "        # creamos las conexiones nuevas en base al nuevo orden aleatorio\n",
    "        for i in range(len(nodes)-1):\n",
    "            graph.add_edges_from([(nodes[i], nodes[i+1])])\n",
    "        patch_size -= 1\n",
    "        # reemplazamos el orden de una operacion anterior con la actual\n",
    "        node_list[selected_process] = nodes\n",
    "    return graph, node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read():\n",
    "    inp = input(\"Introduzca el nombre del archivo: \")\n",
    "    import csv\n",
    "    with open(inp) as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\")\n",
    "        firstline = True\n",
    "        contPun = 0\n",
    "        contRest = 0\n",
    "        contApVt = 0\n",
    "        contHyR = 0\n",
    "        contID = 0\n",
    "        lista_duplos = []\n",
    "        for i in reader:\n",
    "            if firstline:\n",
    "                firstline = False\n",
    "            else:\n",
    "                a = i[0].split(\";\");\n",
    "                if(a[0] == 'pedido'):\n",
    "                    contID += 1\n",
    "                    lista_duplos.append((contID,contPun))\n",
    "                    dic['PUN'].append(contID)\n",
    "                    contID += 1\n",
    "                    lista_duplos.append((contID,contRest))\n",
    "                    dic['REST'].append(contID)\n",
    "                    contID += 1\n",
    "                    lista_duplos.append((contID,contApVt))\n",
    "                    dic['ApVt'].append(contID)\n",
    "                    contID += 1\n",
    "                    lista_duplos.append((contID,contHyR))\n",
    "                    dic['HyR'].append(contID)\n",
    "                    contPun = 0\n",
    "                    contRest = 0\n",
    "                    contApVt = 0\n",
    "                    contHyR = 0\n",
    "                else:\n",
    "                    listaAux = []\n",
    "                    listaAux.extend([int(a[3]),int(a[10]),int(a[13])])\n",
    "                    maximum = max(listaAux)\n",
    "                    contPun = contPun + (int(a[0]) * maximum)\n",
    "                    listaAux = []\n",
    "                    listaAux.extend([int(a[2]),int(a[4]),int(a[5]),int(a[9]),int(a[11]),int(a[12]),int(a[14])])\n",
    "                    maximum = max(listaAux)\n",
    "                    contRest = contRest + (int(a[0]) * maximum)\n",
    "                    listaAux = []\n",
    "                    listaAux.extend([int(a[6]),int(a[7])])\n",
    "                    maximum = max(listaAux)\n",
    "                    contApVt = contApVt + (int(a[0]) * maximum)\n",
    "                    contHyR = contHyR + (int(a[0]) * int(a[8]))\n",
    "        return lista_duplos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write(lista_orden):\n",
    "    counter = 0\n",
    "    lista_procesos_ordenados = []\n",
    "    listaPUN = lista_orden[0]\n",
    "    listaREST = lista_orden[1]\n",
    "    listaApVt = lista_orden[2]\n",
    "    listaHyR = lista_orden[3]\n",
    "\n",
    "    lista_pedidos_PUN = []\n",
    "    lista_pedidos_PUN.append('PUN')\n",
    "    for idCorr in listaPUN:\n",
    "        counter = 0\n",
    "        for id_proceso in dic['PUN']:\n",
    "            if idCorr == id_proceso:\n",
    "                desp = 'Pedido ' + str(counter+1)\n",
    "                lista_pedidos_PUN.append(desp)\n",
    "                break\n",
    "            counter +=1\n",
    "\n",
    "    lista_pedidos_REST = []\n",
    "    lista_pedidos_REST.append('REST')\n",
    "    for idCorr in listaREST:\n",
    "        counter = 0\n",
    "        for id_proceso in dic['REST']:\n",
    "            if idCorr == id_proceso:\n",
    "                desp = 'Pedido ' + str(counter+1)\n",
    "                lista_pedidos_REST.append(desp)\n",
    "                break\n",
    "            counter +=1\n",
    "    \n",
    "    lista_pedidos_ApVT = []\n",
    "    lista_pedidos_ApVT.append('ApVt')\n",
    "    for idCorr in listaApVt:\n",
    "        counter = 0\n",
    "        for id_proceso in dic['ApVt']:\n",
    "            if idCorr == id_proceso:\n",
    "                desp = 'Pedido ' + str(counter+1)\n",
    "                lista_pedidos_ApVT.append(desp)\n",
    "                break\n",
    "            counter +=1\n",
    "\n",
    "    lista_pedidos_HyR = []\n",
    "    lista_pedidos_HyR.append('HyR')\n",
    "    for idCorr in listaHyR:\n",
    "        counter = 0\n",
    "        for id_proceso in dic['HyR']:\n",
    "            if idCorr == id_proceso:\n",
    "                desp = 'Pedido ' + str(counter+1)\n",
    "                lista_pedidos_HyR.append(desp)\n",
    "                break\n",
    "            counter +=1\n",
    "        \n",
    "    lista_procesos_ordenados.append(lista_pedidos_PUN)\n",
    "    lista_procesos_ordenados.append(lista_pedidos_REST)\n",
    "    lista_procesos_ordenados.append(lista_pedidos_ApVT)\n",
    "    lista_procesos_ordenados.append(lista_pedidos_HyR)\n",
    "    cnt = 0\n",
    "    for index in lista_procesos_ordenados:\n",
    "        print(lista_procesos_ordenados[cnt])\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduzca el nombre del archivo: prueba.csv\n",
      " > it=1, patch_size=2.85, f=58343\n",
      " > it=13, patch_size=1.54003, f=57197\n",
      " > it=26, patch_size=0.79056, f=55985\n",
      " > it=73, patch_size=0.0709487, f=55846\n",
      " > it=84, patch_size=0.0403556, f=55709\n",
      " > it=90, patch_size=0.0296651, f=55529\n"
     ]
    }
   ],
   "source": [
    "# CLEVER ALGORITHM: Bees Algorithm\n",
    "# Author: Santiago E. Conant-Pablos, October 6, 2015\n",
    "\n",
    "def objective_function(graph):\n",
    "    \"\"\"returns value of function to optimize\"\"\"\n",
    "    return graph.makespan\n",
    "\n",
    "def create_random_bee(graph, no_processes, no_orders):\n",
    "    \"\"\"create a random bee position\"\"\"\n",
    "    return generate_random_solution(graph, no_processes, no_orders)\n",
    "\n",
    "def create_neigh_bee(graph, node_list, patch_size):\n",
    "    \"\"\"create a bee inside a neighborhood\"\"\"\n",
    "    return perturbate_solution(graph, node_list, patch_size)\n",
    "\n",
    "def search_neigh(parent, neigh_size, patch_size, node_list):\n",
    "    \"\"\"search inside the neighborhood of a site\"\"\"\n",
    "    neigh = []\n",
    "    for i in range(neigh_size):\n",
    "        bee = list(create_neigh_bee(parent, node_list, patch_size))\n",
    "        if len(bee) < 3: # si no se le ha asignado un fitness hay que hacerlo\n",
    "            bee.append(objective_function(bee[0]))\n",
    "        else: # de lo contrario solo hay que reemplazarlo\n",
    "            bee[2] = objective_function(bee[0])\n",
    "        neigh.append(bee)\n",
    "    neigh.sort(key=lambda b: b[2])\n",
    "    return neigh[0]\n",
    "\n",
    "def create_scout_bees(requests, no_processes, no_orders, num_scouts):\n",
    "    \"\"\"creates scout bees for new sites\"\"\"\n",
    "    return [create_random_bee(generate_nodes(requests), no_processes, no_orders) for i in range(num_scouts)]\n",
    "\n",
    "def bees_algorithm(max_gens, requests, no_processes, num_bees, num_sites,\n",
    "                   elite_sites, patch_size, patch_dec, e_bees, o_bees):\n",
    "    \"\"\"implements the Bees algorithm\"\"\"\n",
    "    # el mejor encontrado\n",
    "    best = None\n",
    "    # creacion de una poblacion de soluciones aleatorias\n",
    "    no_requests = int(len(requests)/no_processes)\n",
    "    # pop[i] = (graph, solution, fitness); fitness se agrega en el for interno\n",
    "    pop = [create_random_bee(generate_nodes(\n",
    "        requests), no_processes, no_requests\n",
    "    ) for i in range(num_bees)]\n",
    "    # corre la optimizacion en terminos de generaciones\n",
    "    for gen in range(max_gens):\n",
    "        print_flag = False\n",
    "        for bee in range(num_bees):\n",
    "            pop[bee] = list(pop[bee])\n",
    "            if len(pop[bee]) < 3:\n",
    "                pop[bee].append(objective_function(pop[bee][0]))\n",
    "            else:\n",
    "                pop[bee][2] = objective_function(pop[bee][0])\n",
    "        pop.sort(key = lambda b: b[2])\n",
    "        if not best or pop[0][2] < best[2]:\n",
    "            print_flag = True\n",
    "            best = pop[0]\n",
    "        next_gen = []\n",
    "        for i, parent in enumerate(pop[:num_sites]):\n",
    "            neigh_size = e_bees if i < elite_sites else o_bees\n",
    "            next_gen.append(search_neigh(parent[0], neigh_size, patch_size, parent[1]))\n",
    "        \n",
    "        scouts = create_scout_bees(requests, no_processes, no_requests, num_bees - num_sites)\n",
    "        pop = next_gen + scouts\n",
    "        patch_size = patch_size * patch_dec\n",
    "        if print_flag : print(\" > it=%d, patch_size=%g, f=%g\" % (gen+1,patch_size,best[2]))\n",
    "    return best\n",
    "\n",
    "# algorithm configuration\n",
    "max_gens = 100 # maximun number of generations\n",
    "num_bees = 45\n",
    "num_sites = 3\n",
    "elite_sites = 1\n",
    "patch_size = 3.0\n",
    "patch_dec = 0.95 # decrease of patch size in each generation\n",
    "e_bees = 7    # number of elite bees\n",
    "o_bees = 2    # number of other bees\n",
    "no_jobs = 4 # cantidad de operaciones para ensamblaje (incluye varias en paralelo)\n",
    "requests = read()#[(1,50),(2,3),(3,41),(4,94),(5,15),(6,13),(7,34),(8,29),(9,55),(10,73),(11,14),(12,91)]\n",
    "best = bees_algorithm(max_gens, requests, no_jobs, num_bees, num_sites,\n",
    "                      elite_sites, patch_size, patch_dec, e_bees, o_bees)\n",
    "print(\"Done.\\nBest Solution: f=%g\" % (best[2]))\n",
    "write(best[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
