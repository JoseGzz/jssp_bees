{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CPM(nx.DiGraph):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._dirty = True\n",
    "        self._makespan = -1\n",
    "        self._criticalPath = None\n",
    "\n",
    "    def add_node(self, *args, **kwargs):\n",
    "        self._dirty = True\n",
    "        super().add_node(*args, **kwargs)\n",
    "\n",
    "    def add_nodes_from(self, *args, **kwargs):\n",
    "        self._dirty = True\n",
    "        super().add_nodes_from(*args, **kwargs)\n",
    "\n",
    "    def add_edge(self, *args):  # , **kwargs):\n",
    "        self._dirty = True\n",
    "        super().add_edge(*args)  # , **kwargs)\n",
    "\n",
    "    def add_edges_from(self, *args, **kwargs):\n",
    "        self._dirty = True\n",
    "        super().add_edges_from(*args, **kwargs)\n",
    "\n",
    "    def remove_node(self, *args, **kwargs):\n",
    "        self._dirty = True\n",
    "        super().remove_node(*args, **kwargs)\n",
    "\n",
    "    def remove_nodes_from(self, *args, **kwargs):\n",
    "        self._dirty = True\n",
    "        super().remove_nodes_from(*args, **kwargs)\n",
    "\n",
    "    def remove_edge(self, *args):  # , **kwargs):\n",
    "        self._dirty = True\n",
    "        super().remove_edge(*args)  # , **kwargs)\n",
    "\n",
    "    def remove_edges_from(self, *args, **kwargs):\n",
    "        self._dirty = True\n",
    "        super().remove_edges_from(*args, **kwargs)\n",
    "\n",
    "    def _forward(self):\n",
    "        for n in nx.topological_sort(self):\n",
    "            S = max([self.node[j]['C']\n",
    "                     for j in self.predecessors(n)], default=0)\n",
    "            self.add_node(n, S=S, C=S + self.node[n]['p'])\n",
    "\n",
    "    def _backward(self):\n",
    "        for n in nx.topological_sort(self, reverse=True):\n",
    "            Cp = min([self.node[j]['Sp']\n",
    "                      for j in self.successors(n)], default=self._makespan)\n",
    "            self.add_node(n, Sp=Cp - self.node[n]['p'], Cp=Cp)\n",
    "\n",
    "    def _computeCriticalPath(self):\n",
    "        G = set()\n",
    "        for n in self:\n",
    "            if self.node[n]['C'] == self.node[n]['Cp']:\n",
    "                G.add(n)\n",
    "        self._criticalPath = self.subgraph(G)\n",
    "\n",
    "    @property\n",
    "    def makespan(self):\n",
    "        if self._dirty:\n",
    "            self._update()\n",
    "        return self._makespan\n",
    "\n",
    "    @property\n",
    "    def criticalPath(self):\n",
    "        if self._dirty:\n",
    "            self._update()\n",
    "        return self._criticalPath\n",
    "\n",
    "    def _update(self):\n",
    "        self._forward()\n",
    "        self._makespan = max(nx.get_node_attributes(self, 'C').values())\n",
    "        self._backward()\n",
    "        self._computeCriticalPath()\n",
    "        self._dirty = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_nodes(processes):\n",
    "    graph_nodes  = CPM()\n",
    "    for process in processes:\n",
    "        graph_nodes.add_node(process[0], p=process[1])\n",
    "    return graph_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_random_solution(graph_nodes, no_processes, no_requests):\n",
    "    # obtenemos lista en orden de los nodos\n",
    "    nodes = graph_nodes.nodes()\n",
    "    # creamos lista de listas vacias para organizar el orden de los procesos en comun\n",
    "    node_list = [[] for _ in range(no_processes)]\n",
    "    # separamos los nodos de procesos que pertenecen a cada pedido \n",
    "    adjacency_list = [nodes[i:i + no_processes] for i in range(0, len(nodes), no_processes)]\n",
    "    # creamos los arcos para unir los nodos en el orden establecido por el proceso\n",
    "    for lst in adjacency_list:\n",
    "        for i in range(len(lst)-1):\n",
    "            graph_nodes.add_edges_from([(lst[i], lst[i+1])])\n",
    "    # agrupamos los nodos que pertenecen a la misma operacion para asignarlas al azar\n",
    "    nodes = graph_nodes.nodes()\n",
    "    for i in range(len(node_list)):\n",
    "        for j in range(i, len(nodes), no_processes):\n",
    "            node_list[i].append(nodes[j])\n",
    "    # asignar el orden de uso de cada estacion aleatoriamente\n",
    "    for common_processes in node_list:\n",
    "        random.shuffle(common_processes)\n",
    "        for i in range(len(common_processes)-1):\n",
    "            graph_nodes.add_edges_from([(common_processes[i], common_processes[i+1])])\n",
    "    # regresamos el grafo con precedencias\n",
    "    return graph_nodes, node_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "requests = [(1,50),(2,3),(3,41),(4,94),(5,15),(6,13),(7,34),(8,29),(9,55),(10,73),(11,14),(12,91)]\n",
    "requests2 = [(1,5),(2,3),(3,4),(4,9)]\n",
    "no_processes = 4\n",
    "x = generate_nodes(requests)\n",
    "y, node_list = generate_random_solution(x,no_processes, int(len(requests)/no_processes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421\n",
      "[(1, 2), (1, 5), (2, 3), (2, 6), (3, 4), (3, 7), (5, 9), (5, 6), (6, 7), (7, 8), (8, 4), (9, 10), (10, 2), (10, 11), (11, 3), (11, 12), (12, 8)]\n"
     ]
    }
   ],
   "source": [
    "print(y.makespan)\n",
    "print(y.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perturbate_solution(graph, node_list, patch_size):\n",
    "    while patch_size > 0:\n",
    "        # seleccionamos un proceso aleatorio para modificar su orden\n",
    "        selected_process = random.randint(0, len(node_list)-1)\n",
    "        # obtenemos los nodos involucrados en el proceso seleccionado\n",
    "        nodes = node_list[selected_process]\n",
    "        # creamos una lista de tuplas con esos nodos para eliminar sus conexiones\n",
    "        tup_list = []\n",
    "        for i in range(len(nodes)-1):\n",
    "            tup_list.append((nodes[i], nodes[i+1]))\n",
    "        # eliminamos las conexiones entre esos nodos\n",
    "        graph.remove_edges_from(tup_list)\n",
    "        # generamos un nuevo orden aleatorio\n",
    "        random.shuffle(nodes)\n",
    "        # creamos las conexiones nuevas en base al nuevo orden aleatorio\n",
    "        for i in range(len(nodes)-1):\n",
    "            graph.add_edges_from([(nodes[i], nodes[i+1])])\n",
    "        patch_size -= 1\n",
    "    return graph, nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g, nodes = perturbate_solution(y, node_list, 2)\n",
    "g.makespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g, nodes = perturbate_solution(g, node_list)\n",
    "g.makespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CLEVER ALGORITHM: Bees Algorithm\n",
    "# Author: Santiago E. Conant-Pablos, October 6, 2015\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def objective_function(graph):\n",
    "    \"\"\"returns value of function to optimize\"\"\"\n",
    "    return graph.makespan\n",
    "\n",
    "def create_random_bee(graph, node_list):\n",
    "    \"\"\"create a random bee position\"\"\"\n",
    "    return generate_random_solution(graph, node_list)\n",
    "\n",
    "def create_neigh_bee(graph, node_list):\n",
    "    \"\"\"create a bee inside a neighborhood\"\"\"\n",
    "    perturbate_solution(graph, node_list)\n",
    "\n",
    "def search_neigh(parent, neigh_size, patch_size):\n",
    "    \"\"\"search inside the neighborhood of a site\"\"\"\n",
    "    neigh = []\n",
    "    for i in range(neigh_size):\n",
    "        bee = create_neigh_bee(parent, patch_size)\n",
    "        bee['fitness'] = objective_function(bee)\n",
    "        neigh.append(bee)\n",
    "    neigh.sort(key=lambda b: b['fitness'])\n",
    "    return neigh[0]\n",
    "\n",
    "def create_scout_bees(graph, num_scouts):\n",
    "    \"\"\"creates scout bees for new sites\"\"\"\n",
    "    return [create_random_bee(graph, node_list) for i in range(num_scouts)]\n",
    "\n",
    "def bees_algorithm(max_gens, process_nodes, num_bees, num_sites,\n",
    "                   elite_sites, patch_size, patch_dec, e_bees, o_bees):\n",
    "    \"\"\"implements the Bees algorithm\"\"\"\n",
    "    best = None\n",
    "    pop = [create_random_bee(generate_nodes(process_nodes)) for i in range(num_bees)]\n",
    "    \n",
    "    for gen in range(max_gens):\n",
    "        for bee in range(num_bees):\n",
    "            pop[bee]['fitness'] = objective_function(pop[bee])\n",
    "        pop.sort(key = lambda b: b['fitness'])\n",
    "        if not best or pop[0]['fitness'] < best['fitness']:\n",
    "            best = pop[0]\n",
    "        next_gen = []\n",
    "        for i,parent in enumerate(pop[:num_sites]):\n",
    "            neigh_size = e_bees if i < elite_sites else o_bees\n",
    "            next_gen.append(search_neigh(parent, neigh_size, patch_size))\n",
    "            \n",
    "        scouts = create_scout_bees(search_space, num_bees - num_sites)\n",
    "        pop = next_gen + scouts\n",
    "        patch_size = patch_size * patch_dec\n",
    "        print(\" > it=%d, patch_size=%g, f=%g\" % (gen+1,patch_size,best['fitness']))\n",
    "    return best\n",
    "\n",
    "# problem configuration\n",
    "#problem_size = 2 # number of variables\n",
    "#search_space = np.array([[-5, +5] for i in range(problem_size)],float) # domains\n",
    "# algorithm configuration\n",
    "max_gens = 100 # maximun number of generations\n",
    "num_bees = 45\n",
    "num_sites = 3\n",
    "elite_sites = 1\n",
    "patch_size = 3.0\n",
    "patch_dec = 0.95 # decrease of patch size in each generation\n",
    "e_bees = 7    # number of elite bees\n",
    "o_bees = 2    # number of other bees\n",
    "# execute the algorithm\n",
    "requests = [(1,50),(2,3),(3,41),(4,94),(5,15),(6,13),(7,34),(8,29),(9,55),(10,73),(11,14),(12,91)]\n",
    "best = bees_algorithm(max_gens, node_list, num_bees, num_sites,\n",
    "                      elite_sites, patch_size, patch_dec, e_bees, o_bees)\n",
    "print(\"Done.\\nBest Solution: f=%g, v=%s\" % (best['fitness'], best['vector']))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
